{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.data import load\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "#from transformer import positional_encoding, EncoderLayer\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "from transformers import BertTokenizer , TFBertModel\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:04:59.248016Z",
     "iopub.execute_input": "2022-12-10T18:04:59.248494Z",
     "iopub.status.idle": "2022-12-10T18:05:09.643733Z",
     "shell.execute_reply.started": "2022-12-10T18:04:59.248398Z",
     "shell.execute_reply": "2022-12-10T18:05:09.642875Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/config.json\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/vocab.txt\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/flax_model.msgpack\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/whole-word-masking/._bert_config.json\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/whole-word-masking/bert_config.json\n/kaggle/input/huggingface-bert-variants/bert-large-uncased/bert-large-uncased/whole-word-masking/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/384-8bits.tflite\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/tokenizer.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/tf_model.h5\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/384-fp16.tflite\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/vocab.txt\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/384.tflite\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/saved_model.pb\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/._variables\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/._assets\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/._saved_model.pb\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/._.\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/variables/variables.index\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/variables/._variables.index\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/variables/._variables.data-00000-of-00001\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/variables/variables.data-00000-of-00001\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/PaxHeader/assets\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/PaxHeader/variables\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased-distilled-squad/distilbert-base-uncased-distilled-squad/saved_model/PaxHeader/currentdir\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/config.json\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/vocab.txt\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/flax_model.msgpack\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/whole-word-masking/._bert_config.json\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/whole-word-masking/bert_config.json\n/kaggle/input/huggingface-bert-variants/bert-large-cased/bert-large-cased/whole-word-masking/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/config.json\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/vocab.txt\n/kaggle/input/huggingface-bert-variants/bert-base-cased/bert-base-cased/flax_model.msgpack\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/rust_model.ot\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased/vocab.txt\n/kaggle/input/huggingface-bert-variants/distilbert-base-multilingual-cased/distilbert-base-multilingual-cased/config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-multilingual-cased/distilbert-base-multilingual-cased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-multilingual-cased/distilbert-base-multilingual-cased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/distilbert-base-multilingual-cased/distilbert-base-multilingual-cased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-multilingual-cased/distilbert-base-multilingual-cased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-multilingual-cased/distilbert-base-multilingual-cased/vocab.txt\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/rust_model.ot\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/config.json\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/vocab.txt\n/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased/flax_model.msgpack\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/rust_model.ot\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tokenizer.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tf_model.h5\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/vocab.txt\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/saved_model/saved_model.pb\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/saved_model/variables/variables.index\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/saved_model/variables/variables.data-00000-of-00001\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard10of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard40of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard2of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard4of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard57of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard48of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard23of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard22of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard45of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard19of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard39of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard38of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard56of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard41of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard55of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard32of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard15of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard16of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard17of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard36of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard18of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard27of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard58of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard6of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard61of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard53of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard14of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard46of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard33of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard62of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard47of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard54of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard63of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard12of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard8of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard43of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard59of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard13of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard30of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard25of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard1of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard51of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard42of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard7of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard9of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard49of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/model.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard21of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard34of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard3of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard24of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard28of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard31of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard35of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard5of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard20of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard26of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard50of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard29of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard44of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard11of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard37of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard52of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased-distilled-squad/distilbert-base-cased-distilled-squad/tfjs/group1-shard60of63.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased/config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased/tokenizer.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased/tf_model.h5\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased/tokenizer_config.json\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased/pytorch_model.bin\n/kaggle/input/huggingface-bert-variants/distilbert-base-cased/distilbert-base-cased/vocab.txt\n/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n/kaggle/input/feedback-prize-english-language-learning/train.csv\n/kaggle/input/feedback-prize-english-language-learning/test.csv\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "2022-12-10 18:05:09.596141: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# adapted from https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]  # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth  # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000 ** depths)  # (1, depth)\n",
    "    angle_rads = positions * angle_rates  # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention = GlobalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads,\n",
    "                 dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(\n",
    "            vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                         num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # `x` is token-IDs shape: (batch, seq_len)\n",
    "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "        # Add dropout.\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # Shape `(batch_size, seq_len, d_model)`.\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:28:28.107360Z",
     "iopub.execute_input": "2022-12-09T15:28:28.107998Z",
     "iopub.status.idle": "2022-12-09T15:28:28.131883Z",
     "shell.execute_reply.started": "2022-12-09T15:28:28.107961Z",
     "shell.execute_reply": "2022-12-09T15:28:28.130678Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = \"/kaggle/input/\"\n",
    "bert_dir = \"/kaggle/input/huggingface-bert-variants/bert-base-uncased/\"\n",
    "train_df = pd.read_csv(data_dir + 'feedback-prize-english-language-learning/train.csv')\n",
    "test_df = pd.read_csv(data_dir + 'feedback-prize-english-language-learning/test.csv')\n",
    "sample_df = pd.read_csv(data_dir + 'feedback-prize-english-language-learning/sample_submission.csv')\n",
    "bert_path = bert_dir + 'bert-base-uncased'\n",
    "print(train_df.shape, test_df.shape, sample_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-10T18:06:23.298868Z",
     "iopub.execute_input": "2022-12-10T18:06:23.300450Z",
     "iopub.status.idle": "2022-12-10T18:06:23.546333Z",
     "shell.execute_reply.started": "2022-12-10T18:06:23.300390Z",
     "shell.execute_reply": "2022-12-10T18:06:23.545550Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "(3911, 8) (3, 2) (3, 7)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "size = train_df.shape[0]\n",
    "train, validate = int(0.8*size), int(0.2*size)\n",
    "valid_df = train_df.tail(validate).copy()\n",
    "train_df = train_df.head(train).copy()\n",
    "print(train_df.shape, valid_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-10T18:06:39.594288Z",
     "iopub.execute_input": "2022-12-10T18:06:39.594731Z",
     "iopub.status.idle": "2022-12-10T18:06:39.602714Z",
     "shell.execute_reply.started": "2022-12-10T18:06:39.594694Z",
     "shell.execute_reply": "2022-12-10T18:06:39.601493Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "(3128, 8) (782, 8)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Merging Train and Test Data\n",
    "train_size = train_df.shape[0]\n",
    "test_size = test_df.shape[0]\n",
    "print(train_df.shape, test_df.shape, valid_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-10T18:06:39.998699Z",
     "iopub.execute_input": "2022-12-10T18:06:39.999532Z",
     "iopub.status.idle": "2022-12-10T18:06:40.005451Z",
     "shell.execute_reply.started": "2022-12-10T18:06:39.999491Z",
     "shell.execute_reply": "2022-12-10T18:06:40.004301Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "(3128, 8) (3, 2) (782, 8)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text) :\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+','', text)\n",
    "    text = re.sub(r'@[0-9a-zA-Z]*\\W+',' ' , text)\n",
    "\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'\\#', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    list_text = text.split()\n",
    "    text = ' '.join(list_text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-10T18:06:40.440507Z",
     "iopub.execute_input": "2022-12-10T18:06:40.441588Z",
     "iopub.status.idle": "2022-12-10T18:06:40.448805Z",
     "shell.execute_reply.started": "2022-12-10T18:06:40.441506Z",
     "shell.execute_reply": "2022-12-10T18:06:40.447615Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "def encode(input_text):\n",
    "    inputs = tokenizer.batch_encode_plus(input_text,padding='max_length',max_length=max_text_len, truncation=True)\n",
    "    return inputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:06:40.950198Z",
     "iopub.execute_input": "2022-12-10T18:06:40.950651Z",
     "iopub.status.idle": "2022-12-10T18:06:41.022510Z",
     "shell.execute_reply.started": "2022-12-10T18:06:40.950614Z",
     "shell.execute_reply": "2022-12-10T18:06:41.021554Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_vocab = set()\n",
    "pos_vocab = list(load('help/tagsets/upenn_tagset.pickle').keys())\n",
    "max_text_len = 0\n",
    "truncate_to = 512\n",
    "for dataset in [train_df, valid_df, test_df]:\n",
    "    #dataset.drop(['text_id'], axis=1, inplace=True)\n",
    "    dataset['full_text'] = dataset['full_text'].apply(lambda text : preprocess(text))\n",
    "    dataset['pos_tag'] = dataset['full_text'].apply(lambda text: pos_tag(word_tokenize(text)))\n",
    "    # there are 36 possible pos_tags\n",
    "    dataset['pos'] = dataset['pos_tag'].apply(lambda text: ' '.join([elem[1] for elem in text[:truncate_to]]))\n",
    "    dataset['tokens'] = dataset['pos_tag'].apply(lambda text: [elem[0] for elem in text[:truncate_to]])\n",
    "    for tokens in dataset['tokens']:\n",
    "        text_vocab.update(tokens)\n",
    "        max_text_len = max(max_text_len, len(tokens))\n",
    "    dataset['tokens'] = dataset['tokens'].apply(lambda text: ' '.join(text))\n",
    "#     dataset.drop(['full_text'], axis=1, inplace=True)\n",
    "    dataset.drop(['pos_tag'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-10T18:06:41.526083Z",
     "iopub.execute_input": "2022-12-10T18:06:41.526817Z",
     "iopub.status.idle": "2022-12-10T18:08:06.023499Z",
     "shell.execute_reply.started": "2022-12-10T18:06:41.526779Z",
     "shell.execute_reply": "2022-12-10T18:08:06.022333Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_bert = encode(train_df['tokens'].values.tolist())['input_ids']\n",
    "valid_bert = encode(valid_df['tokens'].values.tolist())['input_ids']\n",
    "test_bert = encode(test_df['tokens'].values.tolist())['input_ids']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:08:33.001350Z",
     "iopub.execute_input": "2022-12-10T18:08:33.002345Z",
     "iopub.status.idle": "2022-12-10T18:08:37.877725Z",
     "shell.execute_reply.started": "2022-12-10T18:08:33.002296Z",
     "shell.execute_reply": "2022-12-10T18:08:37.875612Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27/1698489886.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain_bert\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tokens'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'input_ids'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mvalid_bert\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tokens'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'input_ids'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtest_bert\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'tokens'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'input_ids'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_27/217206964.py\u001B[0m in \u001B[0;36mencode\u001B[0;34m(input_text)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbert_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_encode_plus\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_text\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'max_length'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmax_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_text_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtruncation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mbatch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2701\u001B[0m             \u001B[0mreturn_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_length\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2702\u001B[0m             \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2703\u001B[0;31m             \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2704\u001B[0m         )\n\u001B[1;32m   2705\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36m_batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    731\u001B[0m                 \u001B[0mids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpair_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mids_or_pair_ids\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    732\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 733\u001B[0;31m             \u001B[0mfirst_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_input_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    734\u001B[0m             \u001B[0msecond_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_input_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpair_ids\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpair_ids\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    735\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfirst_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msecond_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36mget_input_ids\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m    698\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mget_input_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    699\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 700\u001B[0;31m                 \u001B[0mtokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    701\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_tokens_to_ids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    702\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36mtokenize\u001B[0;34m(self, text, **kwargs)\u001B[0m\n\u001B[1;32m    512\u001B[0m             ]\n\u001B[1;32m    513\u001B[0m             \u001B[0mpattern\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mr\"(\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr\"|\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mescaped_special_toks\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr\")|\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr\"(.+?)\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 514\u001B[0;31m             \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    515\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    516\u001B[0m         \u001B[0mno_split_token\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique_no_split_tokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/re.py\u001B[0m in \u001B[0;36msub\u001B[0;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[0ma\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mit\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0ms\u001B[0m \u001B[0mpassed\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mMatch\u001B[0m \u001B[0mobject\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mmust\u001B[0m \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m     a replacement string to be used.\"\"\"\n\u001B[0;32m--> 194\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_compile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstring\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    195\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msubn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrepl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstring\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(m)\u001B[0m\n\u001B[1;32m    512\u001B[0m             ]\n\u001B[1;32m    513\u001B[0m             \u001B[0mpattern\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mr\"(\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr\"|\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mescaped_special_toks\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr\")|\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr\"(.+?)\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 514\u001B[0;31m             \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpattern\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    515\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    516\u001B[0m         \u001B[0mno_split_token\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique_no_split_tokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_df['bert'] = train_bert\n",
    "valid_df['bert'] = valid_bert\n",
    "test_df['bert'] = test_bert"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:46.123556Z",
     "iopub.execute_input": "2022-12-09T15:47:46.124452Z",
     "iopub.status.idle": "2022-12-09T15:47:46.132686Z",
     "shell.execute_reply.started": "2022-12-09T15:47:46.124406Z",
     "shell.execute_reply": "2022-12-09T15:47:46.131633Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_df.iloc[0]['tokens'].split())\n",
    "len(train_bert[0])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:46.893455Z",
     "iopub.execute_input": "2022-12-09T15:47:46.893929Z",
     "iopub.status.idle": "2022-12-09T15:47:46.902243Z",
     "shell.execute_reply.started": "2022-12-09T15:47:46.893892Z",
     "shell.execute_reply": "2022-12-09T15:47:46.901278Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_data = pd.concat((train_df, valid_df, test_df)).reset_index(drop=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:08:41.267229Z",
     "iopub.execute_input": "2022-12-10T18:08:41.268249Z",
     "iopub.status.idle": "2022-12-10T18:08:41.279377Z",
     "shell.execute_reply.started": "2022-12-10T18:08:41.268199Z",
     "shell.execute_reply": "2022-12-10T18:08:41.278316Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(all_data['grammar'], all_data['syntax'])\n",
    "plt.xlabel('Grammar Scores')\n",
    "plt.ylabel('Syntax Scores')\n",
    "plt.grid(True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:11:06.910319Z",
     "iopub.execute_input": "2022-12-10T18:11:06.910725Z",
     "iopub.status.idle": "2022-12-10T18:11:07.345697Z",
     "shell.execute_reply.started": "2022-12-10T18:11:06.910691Z",
     "shell.execute_reply": "2022-12-10T18:11:07.344872Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install mpl-scatter-density"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:18:51.562495Z",
     "iopub.execute_input": "2022-12-10T18:18:51.562918Z",
     "iopub.status.idle": "2022-12-10T18:19:03.398768Z",
     "shell.execute_reply.started": "2022-12-10T18:18:51.562877Z",
     "shell.execute_reply": "2022-12-10T18:19:03.397564Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting mpl-scatter-density\n  Downloading mpl_scatter_density-0.7-py3-none-any.whl (655 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m655.5/655.5 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[?25hRequirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.7/site-packages (from mpl-scatter-density) (3.5.3)\nCollecting fast-histogram>=0.3\n  Downloading fast_histogram-0.11-cp36-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.7/52.7 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mpl-scatter-density) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (21.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (3.0.9)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (9.1.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (4.33.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (1.4.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0->mpl-scatter-density) (0.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.0->mpl-scatter-density) (4.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->mpl-scatter-density) (1.15.0)\nInstalling collected packages: fast-histogram, mpl-scatter-density\nSuccessfully installed fast-histogram-0.11 mpl-scatter-density-0.7\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import mpl_scatter_density # adds projection='scatter_density'\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# # \"Viridis-like\" colormap with white background\n",
    "# white_viridis = LinearSegmentedColormap.from_list('white_viridis', [\n",
    "#     (0, '#ffffff'),\n",
    "#     (1e-20, '#440053'),\n",
    "#     (0.2, '#404388'),\n",
    "#     (0.4, '#2a788e'),\n",
    "#     (0.6, '#21a784'),\n",
    "#     (0.8, '#78d151'),\n",
    "#     (1, '#fde624'),\n",
    "# ], N=256)\n",
    "\n",
    "# def using_mpl_scatter_density(fig, x, y):\n",
    "#     ax = fig.add_subplot(1, 1, 1, projection='scatter_density')\n",
    "#     density = ax.scatter_density(x, y, cmap=white_viridis)\n",
    "#     fig.colorbar(density, label='Number of points per pixel')\n",
    "\n",
    "# fig = plt.figure()\n",
    "# using_mpl_scatter_density(fig, all_data['grammar'], all_data['syntax'])\n",
    "# plt.show()\n",
    "x, y = all_data['grammar'], all_data['syntax']\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=50)\n",
    "plt.xlabel('Grammar Scores')\n",
    "plt.ylabel('Syntax Scores')\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:26:46.866429Z",
     "iopub.execute_input": "2022-12-10T18:26:46.866813Z",
     "iopub.status.idle": "2022-12-10T18:26:47.381307Z",
     "shell.execute_reply.started": "2022-12-10T18:26:46.866783Z",
     "shell.execute_reply": "2022-12-10T18:26:47.380269Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-10T18:26:01.079493Z",
     "iopub.execute_input": "2022-12-10T18:26:01.079901Z",
     "iopub.status.idle": "2022-12-10T18:26:01.094938Z",
     "shell.execute_reply.started": "2022-12-10T18:26:01.079868Z",
     "shell.execute_reply": "2022-12-10T18:26:01.093770Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_text_len"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:48.268048Z",
     "iopub.execute_input": "2022-12-09T15:47:48.268750Z",
     "iopub.status.idle": "2022-12-09T15:47:48.275494Z",
     "shell.execute_reply.started": "2022-12-09T15:47:48.268710Z",
     "shell.execute_reply": "2022-12-09T15:47:48.274427Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# tag parts of speech, add as feature\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:48.822498Z",
     "iopub.execute_input": "2022-12-09T15:47:48.823508Z",
     "iopub.status.idle": "2022-12-09T15:47:48.854855Z",
     "shell.execute_reply.started": "2022-12-09T15:47:48.823468Z",
     "shell.execute_reply": "2022-12-09T15:47:48.853740Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \"(E)lement-(Wi)se (Dense)\" Layer for combining two embeddings (or other multi-feature time sequence data) with a Dense layer applied element-wise (so not exactly Dense, as in the output embedding the first position is only determined by a linear combination of the two embedding values in corresponding positions in the two input embeddings)\n",
    "# (We picked this name because it was funny)\n",
    "class EWiDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, activation=None, **kwargs):\n",
    "        super(EWiDense, self).__init__(**kwargs)\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding_size = input_shape[0][-1]\n",
    "        # print(self.tile_shape)\n",
    "        self.w1 = self.add_weight(\n",
    "            shape=[self.embedding_size],\n",
    "            initializer=\"ones\",\n",
    "            trainable=True,\n",
    "            name=\"w1\"\n",
    "        )\n",
    "        # print(tf.shape(self.w1))\n",
    "        self.w2 = self.add_weight(\n",
    "            shape=[self.embedding_size],\n",
    "            initializer=\"ones\",\n",
    "            trainable=True,\n",
    "            name=\"w2\"\n",
    "        )\n",
    "        self.b1 = self.add_weight(\n",
    "            shape=[self.embedding_size],\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"b1\"\n",
    "        )\n",
    "\n",
    "    def call(self, data):  # expected x of two embeddings of shape batch_size, seq_len, embedding_size\n",
    "        if self.activation:\n",
    "            return self.activation(tf.multiply(data[0], self.w1) + tf.multiply(data[1], self.w2) + self.b1)\n",
    "        return tf.multiply(data[0], self.w1) + tf.multiply(data[1], self.w2) + self.b1"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:56.256713Z",
     "iopub.execute_input": "2022-12-09T15:47:56.257093Z",
     "iopub.status.idle": "2022-12-09T15:47:56.267329Z",
     "shell.execute_reply.started": "2022-12-09T15:47:56.257061Z",
     "shell.execute_reply": "2022-12-09T15:47:56.266125Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# compare standard positional encoding with grammar + positional encodinng\n",
    "# use encoder networks, but not the decoders because we don't have an output sequence really\n",
    "\n",
    "class GrammarModel(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               max_text_len, text_vocab, pos_vocab, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.text_vectorization = tf.keras.layers.TextVectorization(output_mode='int', output_sequence_length=max_text_len)\n",
    "            self.text_vectorization.adapt(text_vocab)\n",
    "            self.pos_vectorization = tf.keras.layers.TextVectorization(output_mode='int', output_sequence_length=max_text_len)\n",
    "            self.pos_vectorization.adapt(pos_vocab)\n",
    "            self.word_embedding = tf.keras.layers.Embedding(self.text_vectorization.vocabulary_size(), d_model) # replace\n",
    "            self.pos_embedding = tf.keras.layers.Embedding(self.pos_vectorization.vocabulary_size(), d_model)\n",
    "        self.EWiDenseLayer = EWiDense(activation=tf.keras.layers.LeakyReLU())\n",
    "        self.pos_encoding = tf.Variable(positional_encoding(length=max_text_len, depth=d_model), trainable=False)\n",
    "        self.pos_scalar = tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                         num_heads=num_heads,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.pooling = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        words = inputs[:, 0]\n",
    "        pos = inputs[:, 1]\n",
    "        # combine embeddings\n",
    "        words = self.text_vectorization(words)\n",
    "        pos = self.pos_vectorization(pos)\n",
    "        x = self.EWiDenseLayer((self.word_embedding(words), self.pos_embedding(pos)))\n",
    "        # add positional encoding\n",
    "        x = x * self.pos_scalar\n",
    "        x = x + self.pos_encoding\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "        # add encoding layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.layernorm(x)\n",
    "        return self.dense(x)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:57.232022Z",
     "iopub.execute_input": "2022-12-09T15:47:57.232407Z",
     "iopub.status.idle": "2022-12-09T15:47:57.246912Z",
     "shell.execute_reply.started": "2022-12-09T15:47:57.232375Z",
     "shell.execute_reply": "2022-12-09T15:47:57.245719Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SyntaxModel(GrammarModel):\n",
    "    def __init__(self, hidden_size, *args, **kwargs):\n",
    "        super(SyntaxModel, self).__init__(*args, **kwargs)\n",
    "        self.inter_dense = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "        self.syntax_dense = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        words = inputs[:, 0]\n",
    "        pos = inputs[:, 1]\n",
    "        # combine embeddings\n",
    "        words = self.text_vectorization(words)\n",
    "        pos = self.pos_vectorization(pos)\n",
    "        x = self.EWiDenseLayer((self.word_embedding(words), self.pos_embedding(pos)))\n",
    "        # add positional encoding\n",
    "        x = x * self.pos_scalar\n",
    "        x = x + self.pos_encoding\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "        # add encoding layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.layernorm(x)\n",
    "        self.encoder_out = x #(batch_size, embed_size)\n",
    "        grammar_out = self.dense(x) #(batch_size, 1)\n",
    "        \n",
    "        concatenated = tf.concat((self.encoder_out, grammar_out), axis=1)\n",
    "        x = self.inter_dense(concatenated)\n",
    "        syntax_out = self.syntax_dense(x)\n",
    "        return tf.concat((grammar_out, syntax_out), axis=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.252506Z",
     "iopub.execute_input": "2022-12-09T05:44:06.253109Z",
     "iopub.status.idle": "2022-12-09T05:44:06.263439Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.253077Z",
     "shell.execute_reply": "2022-12-09T05:44:06.262665Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BERTSyntaxModel(GrammarModel):\n",
    "    def __init__(self, hidden_size, *args, **kwargs):\n",
    "        super(BERTSyntaxModel, self).__init__(*args, **kwargs)\n",
    "        del self.word_embedding\n",
    "        del self.text_vectorization\n",
    "        self.inter_dense = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "        self.syntax_dense = tf.keras.layers.Dense(1)\n",
    "        self.bert_encoder = TFBertModel.from_pretrained(bert_path)\n",
    "        for param in self.bert_encoder.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.bert_down_size = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        words = inputs[0]\n",
    "        pos = inputs[1]\n",
    "        # combine embeddings\n",
    "        embedding = self.bert_encoder(words, training=training)[0]\n",
    "        embedding = self.bert_down_size(embedding)\n",
    "        pos = self.pos_vectorization(pos)\n",
    "        x = self.EWiDenseLayer((embedding, self.pos_embedding(pos)))\n",
    "        # add positional encoding\n",
    "        x = x * self.pos_scalar\n",
    "        x = x + self.pos_encoding\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "        # add encoding layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.layernorm(x)\n",
    "        self.encoder_out = x #(batch_size, embed_size)\n",
    "        grammar_out = self.dense(x) #(batch_size, 1)\n",
    "        \n",
    "        concatenated = tf.concat((self.encoder_out, grammar_out), axis=1)\n",
    "        x = self.inter_dense(concatenated)\n",
    "        syntax_out = self.syntax_dense(x)\n",
    "        return tf.concat((grammar_out, syntax_out), axis=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:59.527425Z",
     "iopub.execute_input": "2022-12-09T15:47:59.528373Z",
     "iopub.status.idle": "2022-12-09T15:47:59.541231Z",
     "shell.execute_reply.started": "2022-12-09T15:47:59.528335Z",
     "shell.execute_reply": "2022-12-09T15:47:59.540278Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Column-wise RMSE\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    mcrmse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    return tf.reduce_mean(tf.sqrt(mcrmse), axis=-1, keepdims=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:47:59.937246Z",
     "iopub.execute_input": "2022-12-09T15:47:59.937613Z",
     "iopub.status.idle": "2022-12-09T15:47:59.943179Z",
     "shell.execute_reply.started": "2022-12-09T15:47:59.937561Z",
     "shell.execute_reply": "2022-12-09T15:47:59.941846Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model():\n",
    "    num_layers = 6\n",
    "    d_model = 64\n",
    "    dff = 256\n",
    "    num_heads = 8\n",
    "    dropout_rate = 0.2\n",
    "    model = GrammarModel(num_layers, d_model, num_heads, dff, max_text_len, np.array(list(text_vocab)), np.array(list(pos_vocab)), dropout_rate)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5, clipnorm=1), loss=MCRMSE, metrics=MCRMSE, run_eagerly=True)\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:48:00.538328Z",
     "iopub.execute_input": "2022-12-09T15:48:00.538709Z",
     "iopub.status.idle": "2022-12-09T15:48:00.544975Z",
     "shell.execute_reply.started": "2022-12-09T15:48:00.538677Z",
     "shell.execute_reply": "2022-12-09T15:48:00.543956Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TransformerScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, scale_lr, hidden_size, warmup_steps):\n",
    "        self.scale_lr = tf.cast(scale_lr, tf.float32)\n",
    "        self.hidden_size = tf.cast(hidden_size, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        lr = self.scale_lr / tf.sqrt(self.hidden_size)\n",
    "        lr *= tf.minimum(1 / tf.sqrt(step), step * self.warmup_steps ** (-1.5))\n",
    "        return lr \n",
    "\n",
    "def create_syntax_model():\n",
    "    num_layers = 6\n",
    "    d_model = 64\n",
    "    dff = 256\n",
    "    num_heads = 8\n",
    "    dropout_rate = 0.2\n",
    "    model = BERTSyntaxModel(128, num_layers, d_model, num_heads, dff, max_text_len, np.array(list(text_vocab)), np.array(list(pos_vocab)), dropout_rate)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, clipnorm=1), loss=MCRMSE, metrics=MCRMSE, run_eagerly=True)\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:48:17.949625Z",
     "iopub.execute_input": "2022-12-09T15:48:17.950094Z",
     "iopub.status.idle": "2022-12-09T15:48:17.969101Z",
     "shell.execute_reply.started": "2022-12-09T15:48:17.950053Z",
     "shell.execute_reply": "2022-12-09T15:48:17.968047Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model = create_model()\n",
    "# model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.311197Z",
     "iopub.execute_input": "2022-12-09T05:44:06.311783Z",
     "iopub.status.idle": "2022-12-09T05:44:06.325856Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.311749Z",
     "shell.execute_reply": "2022-12-09T05:44:06.324145Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# len(train_df.iloc[0][['tokens', 'pos']][0].split())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.328124Z",
     "iopub.execute_input": "2022-12-09T05:44:06.329051Z",
     "iopub.status.idle": "2022-12-09T05:44:06.336637Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.329015Z",
     "shell.execute_reply": "2022-12-09T05:44:06.335164Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model.text_vectorization.vocabulary_size()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.338130Z",
     "iopub.execute_input": "2022-12-09T05:44:06.339200Z",
     "iopub.status.idle": "2022-12-09T05:44:06.345490Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.339164Z",
     "shell.execute_reply": "2022-12-09T05:44:06.344072Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_text_len"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:48:10.347294Z",
     "iopub.execute_input": "2022-12-09T15:48:10.347681Z",
     "iopub.status.idle": "2022-12-09T15:48:10.353856Z",
     "shell.execute_reply.started": "2022-12-09T15:48:10.347648Z",
     "shell.execute_reply": "2022-12-09T15:48:10.352871Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model(tf.expand_dims(tf.convert_to_tensor(train_df.iloc[0][['tokens', 'pos']]), 0))\n",
    "# model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.364521Z",
     "iopub.execute_input": "2022-12-09T05:44:06.365876Z",
     "iopub.status.idle": "2022-12-09T05:44:06.370019Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.365817Z",
     "shell.execute_reply": "2022-12-09T05:44:06.368952Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# tf.debugging.disable_traceback_filtering()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.373353Z",
     "iopub.execute_input": "2022-12-09T05:44:06.374145Z",
     "iopub.status.idle": "2022-12-09T05:44:06.382182Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.374101Z",
     "shell.execute_reply": "2022-12-09T05:44:06.380267Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.383473Z",
     "iopub.execute_input": "2022-12-09T05:44:06.384132Z",
     "iopub.status.idle": "2022-12-09T05:44:06.388869Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.384090Z",
     "shell.execute_reply": "2022-12-09T05:44:06.387552Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# checkpoint_filepath = 'tmp/checkpoint'\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_filepath,\n",
    "#     monitor=\"val_loss\",\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     mode='min',\n",
    "#     save_best_only=True)\n",
    "# history = model.fit(\n",
    "#                     train_df[['tokens', 'pos']],\n",
    "#                     train_df['grammar'],\n",
    "#                     validation_data = (valid_df[['tokens', 'pos']], valid_df['grammar']),\n",
    "#                     steps_per_epoch= train_df.shape[0]//4,\n",
    "#                     batch_size = 4,\n",
    "#                     epochs= 100,\n",
    "#                     verbose = 1,\n",
    "#                     shuffle= True,\n",
    "#                     callbacks=[model_checkpoint_callback])"
   ],
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.398334Z",
     "iopub.execute_input": "2022-12-09T05:44:06.398935Z",
     "iopub.status.idle": "2022-12-09T05:44:06.404195Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.398900Z",
     "shell.execute_reply": "2022-12-09T05:44:06.402755Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# history"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.405798Z",
     "iopub.execute_input": "2022-12-09T05:44:06.406525Z",
     "iopub.status.idle": "2022-12-09T05:44:06.417283Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.406482Z",
     "shell.execute_reply": "2022-12-09T05:44:06.416200Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model(tf.expand_dims(tf.convert_to_tensor(train_df.iloc[0][['tokens', 'pos']]), 0))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:06.418571Z",
     "iopub.execute_input": "2022-12-09T05:44:06.419235Z",
     "iopub.status.idle": "2022-12-09T05:44:06.425740Z",
     "shell.execute_reply.started": "2022-12-09T05:44:06.419199Z",
     "shell.execute_reply": "2022-12-09T05:44:06.424705Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "syntax_model = create_syntax_model()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-12-09T15:48:21.030783Z",
     "iopub.execute_input": "2022-12-09T15:48:21.031236Z",
     "iopub.status.idle": "2022-12-09T15:48:30.251341Z",
     "shell.execute_reply.started": "2022-12-09T15:48:21.031194Z",
     "shell.execute_reply": "2022-12-09T15:48:30.250480Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test = (np.array(train_df['bert'].values.tolist()), train_df['pos'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:14.382623Z",
     "iopub.execute_input": "2022-12-09T05:44:14.383406Z",
     "iopub.status.idle": "2022-12-09T05:44:14.388093Z",
     "shell.execute_reply.started": "2022-12-09T05:44:14.383368Z",
     "shell.execute_reply": "2022-12-09T05:44:14.386876Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test[1].shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:14.390156Z",
     "iopub.execute_input": "2022-12-09T05:44:14.390616Z",
     "iopub.status.idle": "2022-12-09T05:44:14.398737Z",
     "shell.execute_reply.started": "2022-12-09T05:44:14.390578Z",
     "shell.execute_reply": "2022-12-09T05:44:14.397667Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# syntax_model(test)\n",
    "# syntax_model.summary()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T05:44:14.401379Z",
     "iopub.execute_input": "2022-12-09T05:44:14.401989Z",
     "iopub.status.idle": "2022-12-09T05:44:14.409640Z",
     "shell.execute_reply.started": "2022-12-09T05:44:14.401960Z",
     "shell.execute_reply": "2022-12-09T05:44:14.408677Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 2\n",
    "checkpoint_filepath = 'checkpoints_bert_final/'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "deez_nuts = syntax_model.fit(\n",
    "                    (np.array(train_df['bert'].values.tolist()), train_df['pos']),\n",
    "                    train_df[['grammar', 'syntax']],\n",
    "                    validation_data = ((np.array(valid_df['bert'].values.tolist()), valid_df['pos']), valid_df[['grammar', 'syntax']]),\n",
    "                    steps_per_epoch= train_df.shape[0]//batch_size,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs= 25,\n",
    "                    verbose = 1,\n",
    "                    shuffle= True,\n",
    "                    callbacks=[model_checkpoint_callback])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T15:48:40.505026Z",
     "iopub.execute_input": "2022-12-09T15:48:40.505388Z",
     "iopub.status.idle": "2022-12-09T22:36:02.720951Z",
     "shell.execute_reply.started": "2022-12-09T15:48:40.505356Z",
     "shell.execute_reply": "2022-12-09T22:36:02.719930Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(deez_nuts.history['loss'], label='loss')\n",
    "plt.plot(deez_nuts.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [MSE]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T22:36:02.724233Z",
     "iopub.execute_input": "2022-12-09T22:36:02.724629Z",
     "iopub.status.idle": "2022-12-09T22:36:02.995514Z",
     "shell.execute_reply.started": "2022-12-09T22:36:02.724588Z",
     "shell.execute_reply": "2022-12-09T22:36:02.994481Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "json.dump(deez_nuts.history, open(\"deez_nuts.json\", 'w'))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-09T22:36:02.996860Z",
     "iopub.execute_input": "2022-12-09T22:36:02.997730Z",
     "iopub.status.idle": "2022-12-09T22:36:03.004774Z",
     "shell.execute_reply.started": "2022-12-09T22:36:02.997690Z",
     "shell.execute_reply": "2022-12-09T22:36:03.003901Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
