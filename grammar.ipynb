{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.data import load\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformer import positional_encoding, EncoderLayer\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from transformers import BertTokenizer , TFBertModel\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3911, 8) (3, 2) (3, 7)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"kaggle/input/\"\n",
    "bert_dir = \"kaggle/input/huggingface-bert-variants/bert-base-uncased/\"\n",
    "train_df = pd.read_csv(data_dir + 'feedback-prize-english-language-learning/train.csv')\n",
    "test_df = pd.read_csv(data_dir + 'feedback-prize-english-language-learning/test.csv')\n",
    "sample_df = pd.read_csv(data_dir + 'feedback-prize-english-language-learning/sample_submission.csv')\n",
    "bert_path = bert_dir + 'bert-base-uncased'\n",
    "print(train_df.shape, test_df.shape, sample_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3128, 8) (782, 8)\n"
     ]
    }
   ],
   "source": [
    "size = train_df.shape[0]\n",
    "train, validate = int(0.8*size), int(0.2*size)\n",
    "valid_df = train_df.tail(validate).copy()\n",
    "train_df = train_df.head(train).copy()\n",
    "print(train_df.shape, valid_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3128, 8) (3, 2) (782, 8)\n"
     ]
    }
   ],
   "source": [
    "# Merging Train and Test Data\n",
    "train_size = train_df.shape[0]\n",
    "test_size = test_df.shape[0]\n",
    "print(train_df.shape, test_df.shape, valid_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text) :\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+','', text)\n",
    "    text = re.sub(r'@[0-9a-zA-Z]*\\W+',' ' , text)\n",
    "\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'\\#', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    list_text = text.split()\n",
    "    text = ' '.join(list_text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "text_vocab = set()\n",
    "pos_vocab = list(load('help/tagsets/upenn_tagset.pickle').keys())\n",
    "for dataset in [train_df, valid_df, test_df]:\n",
    "    dataset.drop(['text_id'], axis=1, inplace=True)\n",
    "    dataset['full_text'] = dataset['full_text'].apply(lambda text : preprocess(text))\n",
    "    dataset['pos_tag'] = dataset['full_text'].apply(lambda text: pos_tag(word_tokenize(text)))\n",
    "    # there are 36 possible pos_tags\n",
    "    dataset['pos'] = dataset['pos_tag'].apply(lambda text: ' '.join([elem[1] for elem in text]))\n",
    "    dataset['tokens'] = dataset['pos_tag'].apply(lambda text: [elem[0] for elem in text])\n",
    "    for tokens in dataset['tokens']:\n",
    "        text_vocab.update(tokens)\n",
    "    dataset['tokens'] = dataset['tokens'].apply(lambda text: ' '.join(text))\n",
    "    dataset.drop(['full_text'], axis=1, inplace=True)\n",
    "    dataset.drop(['pos_tag'], axis=1, inplace=True)\n",
    "all_data = pd.concat((train_df, valid_df, test_df)).reset_index(drop=True)\n",
    "max_text_len = max(len(elem) for elem in all_data['tokens'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   cohesion  syntax  vocabulary  phraseology  grammar  conventions  \\\n0       3.5     3.5         3.0          3.0      4.0          3.0   \n1       2.5     2.5         3.0          2.0      2.0          2.5   \n2       3.0     3.5         3.0          3.0      3.0          2.5   \n3       4.5     4.5         4.5          4.5      4.0          5.0   \n4       2.5     3.0         3.0          3.0      2.5          2.5   \n\n                                                 pos  \\\n0  NN VBP IN NNS MD VB IN VBG IN NN , IN PRP VBP ...   \n1  WRB DT NN VBZ DT NN PRP VBP TO VB PRP VB DT JJ...   \n2  NN , JJ IN JJ VBP DT NN NN IN VBG DT NN NN NN ...   \n3  DT JJS NN IN NN VBZ WRB PRP VBP PRP . VB VBP I...   \n4  JJ NN IN NN MD VB IN JJ NNS MD VB NNS TO VB JJ...   \n\n                                              tokens  \n0  i think that students would benefit from learn...  \n1  when a problem is a change you have to let it ...  \n2  dear , principal if u change the school policy...  \n3  the best time in life is when you become yours...  \n4  small act of kindness can impact in other peop...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>pos</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>NN VBP IN NNS MD VB IN VBG IN NN , IN PRP VBP ...</td>\n      <td>i think that students would benefit from learn...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>WRB DT NN VBZ DT NN PRP VBP TO VB PRP VB DT JJ...</td>\n      <td>when a problem is a change you have to let it ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>NN , JJ IN JJ VBP DT NN NN IN VBG DT NN NN NN ...</td>\n      <td>dear , principal if u change the school policy...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>DT JJS NN IN NN VBZ WRB PRP VBP PRP . VB VBP I...</td>\n      <td>the best time in life is when you become yours...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>JJ NN IN NN MD VB IN JJ NNS MD VB NNS TO VB JJ...</td>\n      <td>small act of kindness can impact in other peop...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag parts of speech, add as feature\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "# \"(E)lement-(Wi)se (Dense)\" Layer for combining two embeddings (or other multi-feature time sequence data) with a Dense layer applied element-wise (so not exactly Dense, as in the output embedding the first position is only determined by a linear combination of the two embedding values in corresponding positions in the two input embeddings)\n",
    "# (We picked this name because it was funny)\n",
    "class EWiDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, activation=None, **kwargs):\n",
    "        super(EWiDense, self).__init__(**kwargs)\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding_size = input_shape[0][-1]\n",
    "        self.tile_shape = input_shape[0][1:-1]\n",
    "        self.tile_shape = tf.concat([self.tile_shape, tf.convert_to_tensor([1])], 0)\n",
    "        # print(self.tile_shape)\n",
    "        self.w1 = self.add_weight(\n",
    "            shape=(1, self.embedding_size),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        # print(tf.shape(tf.tile(self.w1, self.tile_shape)))\n",
    "        self.w2 = self.add_weight(\n",
    "            shape=(1, self.embedding_size),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b1 = self.add_weight(\n",
    "            shape=(1, self.embedding_size),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, data):  # expected x of two embeddings of shape batch_size, seq_len, embedding_size\n",
    "        if self.activation:\n",
    "            return self.activation(tf.multiply(data[0], tf.tile(self.w1, self.tile_shape)) + tf.multiply(data[1], tf.tile(self.w2, self.tile_shape)) + tf.tile(self.b1, self.tile_shape))\n",
    "        return tf.multiply(data[0], tf.tile(self.w1, self.tile_shape)) + tf.multiply(data[1], tf.tile(self.w2, self.tile_shape)) + tf.tile(self.b1, self.tile_shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "# compare standard positional encoding with grammar + positional encodinng\n",
    "# use encoder networks, but not the decoders because we don't have an output sequence really\n",
    "\n",
    "class GrammarModel(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               max_text_len, text_vocab, pos_vocab, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.text_vectorization = tf.keras.layers.TextVectorization(output_mode='int', output_sequence_length=max_text_len)\n",
    "        self.text_vectorization.adapt(text_vocab)\n",
    "        self.pos_vectorization = tf.keras.layers.TextVectorization(output_mode='int', output_sequence_length=max_text_len)\n",
    "        self.pos_vectorization.adapt(pos_vocab)\n",
    "        self.word_embedding = tf.keras.layers.Embedding(self.text_vectorization.vocabulary_size(), d_model) # replace\n",
    "        self.pos_embedding = tf.keras.layers.Embedding(self.pos_vectorization.vocabulary_size(), d_model)\n",
    "        self.EWiDenseLayer = EWiDense(activation=tf.keras.layers.LeakyReLU())\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "        # self.enc_layers = [\n",
    "        #     EncoderLayer(d_model=d_model,\n",
    "        #                  num_heads=num_heads,\n",
    "        #                  dff=dff,\n",
    "        #                  dropout_rate=dropout_rate)\n",
    "        #     for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.pooling = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        words = inputs[:, 0]\n",
    "        pos = inputs[:, 1]\n",
    "        length = tf.shape(words)[0] # seq_len\n",
    "        # combine embeddings\n",
    "        words = self.text_vectorization(words)\n",
    "        pos = self.pos_vectorization(pos)\n",
    "        x = self.EWiDenseLayer((self.word_embedding(words), self.pos_embedding(pos)))\n",
    "        # add positional encoding\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "        # add encoding layers\n",
    "        # for i in range(self.num_layers):\n",
    "        #     x = self.enc_layers[i](x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.layernorm(x)\n",
    "        return self.dense(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "## Column-wise RMSE\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    mcrmse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    return tf.reduce_mean(tf.sqrt(mcrmse), axis=-1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    num_layers = 4\n",
    "    d_model = 128\n",
    "    dff = 512\n",
    "    num_heads = 8\n",
    "    dropout_rate = 0.1\n",
    "    model = GrammarModel(num_layers, d_model, num_heads, dff, max_text_len, np.array(list(text_vocab)), np.array(list(pos_vocab)), dropout_rate)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=MCRMSE, metrics=MCRMSE)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "# model.summary()\n",
    "batch_size = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"grammar_model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_58 (Text  multiple                 0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " text_vectorization_59 (Text  multiple                 0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_55 (Embedding)    multiple                  2758144   \n",
      "                                                                 \n",
      " embedding_56 (Embedding)    multiple                  4608      \n",
      "                                                                 \n",
      " e_wi_dense_28 (EWiDense)    multiple                  384       \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " global_average_pooling1d_26  multiple                 0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " layer_normalization_58 (Lay  multiple                 256       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_58 (Dense)            multiple                  129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,763,521\n",
      "Trainable params: 2,763,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model(tf.expand_dims(tf.convert_to_tensor(train_df.iloc[0][['tokens', 'pos']]), 0))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "tf.debugging.disable_traceback_filtering()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "tf.Tensor([6192    1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([6192  128], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/grammar_model_31/add/BroadcastGradientArgs' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\patri\\AppData\\Local\\Temp/ipykernel_21604/1202085082.py\", line 1, in <module>\n      history = model.fit(\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 61, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/grammar_model_31/add/BroadcastGradientArgs'\nIncompatible shapes: [5,6192,128] vs. [1,5,128]\n\t [[{{node gradient_tape/grammar_model_31/add/BroadcastGradientArgs}}]] [Op:__inference_train_function_93617]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21604/1202085082.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m history = model.fit(\n\u001B[0m\u001B[0;32m      2\u001B[0m                     \u001B[0mtrain_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'tokens'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'pos'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                     \u001B[0mtrain_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'grammar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                     \u001B[0mvalidation_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mvalid_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'tokens'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'pos'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'grammar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                     \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mtrain_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m//\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0merror_handler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdebugging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_traceback_filtering_enabled\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1648\u001B[0m                         ):\n\u001B[0;32m   1649\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1650\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1651\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1652\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_traceback_filtering_enabled\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mNameError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m       \u001B[1;31m# In some very rare cases,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    878\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    943\u001B[0m         \u001B[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    944\u001B[0m         \u001B[1;31m# no_variable_creation function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 945\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_no_variable_creation_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    946\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    947\u001B[0m       _, _, filtered_flat_args = (\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    132\u001B[0m       (concrete_function,\n\u001B[0;32m    133\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[1;33m     return concrete_function._call_flat(\n\u001B[0m\u001B[0;32m    135\u001B[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1743\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1744\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1745\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1746\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1747\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    377\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 378\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    379\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     53\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     54\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'gradient_tape/grammar_model_31/add/BroadcastGradientArgs' defined at (most recent call last):\n    File \"C:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\patri\\AppData\\Local\\Temp/ipykernel_21604/1202085082.py\", line 1, in <module>\n      history = model.fit(\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 61, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"C:\\Users\\patri\\OneDrive\\Documents\\Study\\CSCI 1470\\N-ELL-P\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/grammar_model_31/add/BroadcastGradientArgs'\nIncompatible shapes: [5,6192,128] vs. [1,5,128]\n\t [[{{node gradient_tape/grammar_model_31/add/BroadcastGradientArgs}}]] [Op:__inference_train_function_93617]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "                    train_df[['tokens', 'pos']],\n",
    "                    train_df['grammar'],\n",
    "                    validation_data = (valid_df[['tokens', 'pos']], valid_df['grammar']),\n",
    "                    steps_per_epoch= train_df.shape[0]//batch_size,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs= 100,\n",
    "                    verbose = 1,\n",
    "                    shuffle= True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[['tokens', 'pos']]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
